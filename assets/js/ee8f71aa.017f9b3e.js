"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[9689],{35130:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var t=i(74848),s=i(28453);const a={sidebar_position:5},r="Ollama - AI Model",o={id:"system-architecture/AI",title:"Ollama - AI Model",description:"CodeLlama is an advanced code generation model developed by Meta AI. It is a large language model (LLM) designed specifically for coding tasks, leveraging the LLaMA architecture to provide efficient and high-quality code completion, generation, and understanding capabilities.",source:"@site/docs/system-architecture/AI.md",sourceDirName:"system-architecture",slug:"/system-architecture/AI",permalink:"/actions-test/docs/system-architecture/AI",draft:!1,unlisted:!1,editUrl:"https://github.com/NickRucinski/actions-test/edit/main/documentation/docs/system-architecture/AI.md",tags:[],version:"current",lastUpdatedBy:"HydroLink",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"docsSidebar",previous:{title:"Entity Relation Diagram",permalink:"/actions-test/docs/system-architecture/entity-relation-diagram"},next:{title:"Development Environment",permalink:"/actions-test/docs/system-architecture/development-environment"}},c={},l=[{value:"Key Features",id:"key-features",level:2},{value:"Important Statistics",id:"important-statistics",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Availability",id:"availability",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"ollama---ai-model",children:"Ollama - AI Model"}),"\n",(0,t.jsx)(n.p,{children:"CodeLlama is an advanced code generation model developed by Meta AI. It is a large language model (LLM) designed specifically for coding tasks, leveraging the LLaMA architecture to provide efficient and high-quality code completion, generation, and understanding capabilities."}),"\n",(0,t.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Multiple Model Sizes"}),": Available in different sizes, including 7B, 13B, and 34B parameters, to balance performance and efficiency."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Context Awareness"}),": Handles extended code contexts effectively, making it useful for large-scale software projects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Supports Multiple Languages"}),": Proficient in Python, C++, Java, JavaScript, Bash, and more."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Optimized for Efficiency"}),": Uses improved tokenization and inference techniques to enhance coding performance."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"important-statistics",children:"Important Statistics"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Base Architecture"}),": LLaMA 2"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Model Sizes"}),": 7B, 13B, 34B parameters"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Training Data"}),": Trained on a dataset of publicly available code repositories"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Max Context Length"}),": Up to 100K tokens"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Code Completion"}),": Assists in writing and finishing code snippets efficiently."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Code Generation"}),": Generates entire functions, classes, and scripts based on prompts."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Code Understanding"}),": Helps in debugging and explaining complex code segments."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Refactoring and Optimization"}),": Suggests improvements and optimizations for better performance."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"availability",children:"Availability"}),"\n",(0,t.jsx)(n.p,{children:"CodeLlama is open-source and available for research and commercial use under Meta's licensing terms."}),"\n",(0,t.jsxs)(n.p,{children:["For more details, visit the ",(0,t.jsx)(n.a,{href:"https://github.com/facebookresearch/codellama",children:"official repository"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>o});var t=i(96540);const s={},a=t.createContext(s);function r(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);